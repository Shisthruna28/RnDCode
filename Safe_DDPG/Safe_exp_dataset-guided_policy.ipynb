{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "gym.logger.set_level(40) \n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "torch.manual_seed(0) \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "import random\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torch.utils.data as utils_data\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state space 4 \n",
      "action space 1\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0').unwrapped\n",
    "env.seed(2)\n",
    "n_state=env.observation_space.shape[0] + 1\n",
    "n_actions=env.action_space.shape[0]\n",
    "print(f'state space {n_state} \\naction space {n_actions}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_safe = namedtuple(\"experience_safe\", field_names=[\"state\", \"action\", \"next_state\"])\n",
    "memory = deque(maxlen=1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_init(layer):\n",
    "    fan_in = layer.weight.data.size()[0]\n",
    "    lim = 1. / np.sqrt(fan_in)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_size, action_size, fc1_units=400, fc2_units=300):\n",
    "        super(Actor, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.fc1.weight.data.uniform_(*hidden_init(self.fc1))\n",
    "        self.fc2.weight.data.uniform_(*hidden_init(self.fc2))\n",
    "        self.fc3.weight.data.uniform_(-3e-3, 3e-3)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return torch.tanh(self.fc3(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act(state, add_noise=False):\n",
    "        state = torch.from_numpy(state).float()\n",
    "        actor_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action = actor_local(state).data.numpy()\n",
    "        actor_local.train()\n",
    "        if add_noise:\n",
    "            action += self.noise.sample()\n",
    "        return np.clip(action, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_local = Actor(3, n_actions)\n",
    "actor_local.load_state_dict(torch.load('checkpoint_actor_tmp.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Random Agent\"\"\"\n",
    "Num_episode=10000\n",
    "max_t= 100\n",
    "def random_episode(env):\n",
    "    for episode in range(Num_episode):\n",
    "        state = env.reset()\n",
    "        state_c = np.hstack((state,np.abs(state[2])))\n",
    "        for t in range(max_t):\n",
    "            action=act(state)\n",
    "            next_state,reward,done,_= env.step(action) \n",
    "            next_state_c = np.hstack((next_state,np.abs(next_state[2])))\n",
    "            e = experience_safe(state_c, action, next_state_c)\n",
    "            memory.append(e)\n",
    "            state_c = next_state_c  \n",
    "            state = next_state\n",
    "            if np.abs(state[2]) > 6:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_episode(env)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347832\n"
     ]
    }
   ],
   "source": [
    "print(len(memory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-18-48c4aa66a1c3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-48c4aa66a1c3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "experiences = random.sample(self.memory, k=self.batch_size)\n",
    "states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).float().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "restricting 3 varaible -3 to 3 to allow some slack\n",
    "to allow some slack variable from -2.8 to 2.8\n",
    "saying augument another state (mod velocity) < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Safelayer(nn.Module):\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=10):\n",
    "        super(Safelayer, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, action_size)\n",
    "           \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_size = int(0.8 * len(memory))\n",
    "train_indices = np.random.choice(np.arange(len(memory)), train_set_size, replace = False)\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_indices = np.setdiff1d(np.arange(len(memory)), train_indices, assume_unique= True)\n",
    "val_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = utils_data.DataLoader(memory, batch_size = batch_size, sampler=train_sampler, num_workers=1)\n",
    "valloader = utils_data.DataLoader(memory, batch_size = batch_size, sampler=val_sampler, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(trainloader, phase = 'Training'):\n",
    "    if phase == 'Training':\n",
    "        model.train()\n",
    "    if phase == 'Validation':\n",
    "        model.eval()\n",
    "    total_loss = 0\n",
    "    for i, (state,action,next_state) in enumerate(trainloader):  \n",
    "        states = state.float().to(device)\n",
    "        actions = action.float().to(device)\n",
    "        next_states = next_state.float().to(device)\n",
    "        cs = states[:,-1].view(-1,1).to(device)\n",
    "        cs_p = next_states[:,-1].view(-1,1).to(device)\n",
    "        c = model(states).view(-1,1)\n",
    "        #print(c)\n",
    "        diff = torch.einsum('ij,ij->i', [c, actions]).view(-1,1)\n",
    "        #print(diff)\n",
    "        y_pred = cs+diff\n",
    "        loss = criterion(y_pred,cs)\n",
    "        total_loss += loss.item()\n",
    "        if phase == 'Training':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    return total_loss/len(trainloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0   Train Loss: 0.27819     Val Loss: 0.02118  \n",
      "Epoch: 1   Train Loss: 0.00558     Val Loss: 0.00124  \n",
      "Epoch: 2   Train Loss: 0.00045     Val Loss: 0.00006  \n"
     ]
    }
   ],
   "source": [
    "train_loss_values =[]\n",
    "val_loss_values =[]\n",
    "num_epochs = 3\n",
    "model = Safelayer(n_state,n_actions,121).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr= learning_rate)\n",
    "besval=0\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    train_loss = Train(trainloader)\n",
    "   # Training set accuracy  train_loss_values.append(train_loss)\n",
    "    val_loss = Train(valloader,'Validation')  # Training set accuracy\n",
    "    val_loss_values.append(val_loss)\n",
    "    print(f'Epoch: {epoch}   Train Loss: {train_loss:.5f} \\\n",
    "    Val Loss: {val_loss:.5f}  ')\n",
    "    torch.save(model.state_dict(), 'safe_layer_guided.pth')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2151,  0.1278, -0.1023, -0.1311, -0.1130, -0.1973, -0.1711,  0.0297,\n",
       "          0.0918,  0.0177]], device='cuda:0')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()['fc2.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'safe_layer_guided.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight', tensor([[ 0.0478, -0.1145,  0.3815,  0.1945],\n",
       "                      [ 0.1848,  0.1499,  0.3260,  0.0066],\n",
       "                      [-0.0001,  0.4127, -0.0213, -0.1184],\n",
       "                      [-0.2749,  0.3716,  0.4599,  0.3640],\n",
       "                      [ 0.0371, -0.0674,  0.6275, -0.3252],\n",
       "                      [ 0.3398, -0.2197, -0.0225,  0.0680],\n",
       "                      [ 0.1296, -0.1586,  0.1447,  0.2567],\n",
       "                      [ 0.2024, -0.1572, -0.2074,  0.4135],\n",
       "                      [ 0.1608,  0.1184,  0.4054,  0.0735],\n",
       "                      [ 0.3036, -0.0972, -0.2475, -0.3242]], device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.3280, -0.2559,  0.3603,  0.2388,  0.4980,  0.2227,  0.3507,  0.3689,\n",
       "                      -0.2879, -0.0483], device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[ 0.2147,  0.1285, -0.0586, -0.1310, -0.1120, -0.1986, -0.1697,  0.0354,\n",
       "                        0.0923,  0.0185]], device='cuda:0')),\n",
       "             ('fc2.bias', tensor([0.2041], device='cuda:0'))])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.0/0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
